import tkinter as tk
from tkinter import filedialog, messagebox
import customtkinter as ctk
from PIL import Image, ImageTk, ImageOps
import cv2
import numpy as np
import os
import glob
import threading
import random
import time
from datetime import datetime

# --- C·∫§U H√åNH GIAO DI·ªÜN ---
ctk.set_appearance_mode("Dark")
ctk.set_default_color_theme("dark-blue")

APP_NAME = "Yoga Pose AI Pro - Video Analytics"
WINDOW_WIDTH = 1366
WINDOW_HEIGHT = 768

# --- KHU V·ª∞C IMPORT MODEL ---
try:
    from src.detection_keypoint import DetectKeypoint
    from src.classification_keypoint import KeypointClassification
    MODEL_LOADED = True
except ImportError:
    MODEL_LOADED = False
    print("‚ö†Ô∏è C·∫¢NH B√ÅO: ƒêang ch·∫°y ch·∫ø ƒë·ªô Demo (Kh√¥ng c√≥ Model th·ª±c).")

class YogaApp(ctk.CTk):
    def __init__(self):
        super().__init__()

        # Setup C·ª≠a s·ªï ch√≠nh
        self.title(APP_NAME)
        
        # CƒÉn gi·ªØa m√†n h√¨nh
        screen_width = self.winfo_screenwidth()
        screen_height = self.winfo_screenheight()
        x_cordinate = int((screen_width / 2) - (WINDOW_WIDTH / 2))
        y_cordinate = int((screen_height / 2) - (WINDOW_HEIGHT / 2))
        self.geometry(f"{WINDOW_WIDTH}x{WINDOW_HEIGHT}+{x_cordinate}+{y_cordinate}")
        self.minsize(1024, 600)
        
        # Load Model
        self.detection_model = None
        self.classification_model = None
        self.init_models()

        # Layout Ch√≠nh
        self.grid_columnconfigure(1, weight=1)
        self.grid_rowconfigure(0, weight=1)

        # 1. SIDEBAR (Menu tr√°i)
        self.create_sidebar()

        # 2. TABVIEW (Khu v·ª±c ch√≠nh)
        self.create_main_view()

        # Bi·∫øn tr·∫°ng th√°i
        self.current_image = None
        self.current_pil_image = None
        self.current_result_image = None
        
        # Bi·∫øn cho Video Control
        self.is_video_mode = False
        self.cap = None
        self.video_running = False
        self.is_paused = False
        self.video_delay = 30  # ms (default ~30fps)
        self.current_frame_cv = None # L∆∞u frame hi·ªán t·∫°i ƒë·ªÉ save

        # Load sample images ban ƒë·∫ßu
        self.after(500, self.load_sample_images_ui)

    def init_models(self):
        if MODEL_LOADED:
            try:
                # L∆∞u √Ω: V·ªõi Video real-time, n√™n d√πng yolov8n-pose.pt (nano) ƒë·ªÉ nhanh h∆°n n·∫øu m√°y y·∫øu
                self.detection_model = DetectKeypoint("yolov8m-pose.pt")
                self.classification_model = KeypointClassification("./models/pose_classification.pth")
                print("‚úÖ Models loaded successfully.")
            except Exception as e:
                print(f"‚ùå Error loading models: {e}")

    def create_sidebar(self):
        self.sidebar_frame = ctk.CTkFrame(self, width=220, corner_radius=0)
        self.sidebar_frame.grid(row=0, column=0, sticky="nsew")
        self.sidebar_frame.grid_rowconfigure(6, weight=1)

        # Logo
        self.logo_label = ctk.CTkLabel(self.sidebar_frame, text="üßò YOGA COACH AI", 
                                       font=ctk.CTkFont(size=22, weight="bold"))
        self.logo_label.grid(row=0, column=0, padx=20, pady=(30, 10))
        
        # --- MODE CONTROL ---
        ctk.CTkLabel(self.sidebar_frame, text="CH·∫æ ƒê·ªò HO·∫†T ƒê·ªòNG", font=("Arial", 12, "bold"), text_color="gray").grid(row=1, column=0, pady=(20, 5))
        
        self.btn_mode_image = ctk.CTkButton(self.sidebar_frame, text="üì∑ Ph√¢n t√≠ch ·∫¢nh", 
                                            fg_color="#00ADB5",
                                            command=self.switch_to_image_mode)
        self.btn_mode_image.grid(row=2, column=0, padx=20, pady=10)

        self.btn_mode_video = ctk.CTkButton(self.sidebar_frame, text="üé• Ph√¢n t√≠ch Video", 
                                            fg_color="transparent", border_width=2, border_color="#E63946", text_color="#E63946",
                                            command=self.switch_to_video_mode)
        self.btn_mode_video.grid(row=3, column=0, padx=20, pady=10)

        # N√∫t Upload (D√πng chung cho c·∫£ 2 ch·∫ø ƒë·ªô)
        self.btn_upload = ctk.CTkButton(self.sidebar_frame, text="üìÇ T·∫£i File L√™n", 
                                        command=self.open_file_dialog,
                                        fg_color="#333", hover_color="#444")
        self.btn_upload.grid(row=4, column=0, padx=20, pady=20)

        # Info Box
        self.info_box = ctk.CTkTextbox(self.sidebar_frame, height=150, fg_color="transparent", text_color="gray")
        self.info_box.insert("0.0", "H∆Ø·ªöNG D·∫™N:\n- Ch·ªçn ch·∫ø ƒë·ªô ·∫¢nh ho·∫∑c Video.\n- B·∫•m 'T·∫£i File L√™n' ƒë·ªÉ ch·ªçn ·∫£nh ho·∫∑c video c·∫ßn ph√¢n t√≠ch.\n- AI s·∫Ω ch·∫°y v√† ƒë√°nh gi√° t·ª´ng khung h√¨nh.")
        self.info_box.configure(state="disabled")
        self.info_box.grid(row=5, column=0, padx=20, pady=10)

        # Settings
        self.appearance_mode_menu = ctk.CTkOptionMenu(self.sidebar_frame, values=["Dark", "Light", "System"],
                                                      command=self.change_appearance_mode_event)
        self.appearance_mode_menu.grid(row=7, column=0, padx=20, pady=(10, 30))

    def create_main_view(self):
        self.tab_view = ctk.CTkTabview(self, fg_color="transparent")
        self.tab_view.grid(row=0, column=1, sticky="nsew", padx=20, pady=10)
        
        self.tab_dashboard = self.tab_view.add("üîç Dashboard Gi√°m S√°t")
        self.setup_dashboard_tab(self.tab_dashboard)

    def setup_dashboard_tab(self, parent):
        parent.grid_columnconfigure((0, 1), weight=1, uniform="equal_cols")
        # Row 0: Area hi·ªÉn th·ªã (·∫¢nh/Video)
        parent.grid_rowconfigure(0, weight=1) 
        # Row 1: Video Controls (·∫®n hi·ªán linh ho·∫°t)
        parent.grid_rowconfigure(1, weight=0)
        # Row 2: Stats Panel
        parent.grid_rowconfigure(2, weight=0)
        # Row 3: Gallery
        parent.grid_rowconfigure(3, weight=0)

        # --- 1. KHUNG INPUT (Camera Raw / ·∫¢nh g·ªëc) ---
        self.frame_input = ctk.CTkFrame(parent, fg_color=("gray90", "#212121"))
        self.frame_input.grid(row=0, column=0, sticky="nsew", padx=5, pady=5)
        self.frame_input.grid_columnconfigure(0, weight=1)
        self.frame_input.grid_rowconfigure(1, weight=1)

        self.lbl_input_title = ctk.CTkLabel(self.frame_input, text="·∫¢NH G·ªêC", font=("Arial", 14, "bold"), text_color="gray")
        self.lbl_input_title.grid(row=0, column=0, pady=5)
        
        self.lbl_img_input = ctk.CTkLabel(self.frame_input, text="S·∫µn s√†ng...", corner_radius=0)
        self.lbl_img_input.grid(row=1, column=0, sticky="nsew", padx=5, pady=5)

        # --- 2. KHUNG OUTPUT (AI Processed) ---
        self.frame_output = ctk.CTkFrame(parent, fg_color=("gray90", "#212121"))
        # M·∫∑c ƒë·ªãnh ban ƒë·∫ßu ·ªü c·ªôt 1 (ch·∫ø ƒë·ªô ·∫£nh)
        self.frame_output.grid(row=0, column=1, sticky="nsew", padx=5, pady=5)
        self.frame_output.grid_columnconfigure(0, weight=1)
        self.frame_output.grid_rowconfigure(1, weight=1)

        self.lbl_output_title = ctk.CTkLabel(self.frame_output, text="K·∫æT QU·∫¢ AI", font=("Arial", 14, "bold"), text_color="#00ADB5")
        self.lbl_output_title.grid(row=0, column=0, pady=5)
        
        self.lbl_img_result = ctk.CTkLabel(self.frame_output, text="K·∫øt qu·∫£ hi·ªÉn th·ªã t·∫°i ƒë√¢y", corner_radius=0)
        self.lbl_img_result.grid(row=1, column=0, sticky="nsew", padx=5, pady=5)

        # --- 3. VIDEO CONTROLS (Thanh ƒëi·ªÅu khi·ªÉn Video) ---
        self.video_controls_frame = ctk.CTkFrame(parent, height=50, fg_color="transparent")
        # M·∫∑c ƒë·ªãnh ·∫©n, ch·ªâ hi·ªán khi switch sang Video Mode
        self.video_controls_frame.grid_remove() 
        
        # N√∫t Gi·∫£m T·ªëc
        ctk.CTkButton(self.video_controls_frame, text="‚è™ Ch·∫≠m", width=80, command=self.slow_down_video).pack(side="left", padx=10)
        # N√∫t Play/Pause
        self.btn_pause = ctk.CTkButton(self.video_controls_frame, text="‚è∏ T·∫°m D·ª´ng", width=100, fg_color="#E63946", command=self.toggle_pause)
        self.btn_pause.pack(side="left", padx=10)
        # N√∫t TƒÉng T·ªëc
        ctk.CTkButton(self.video_controls_frame, text="Nhanh ‚è©", width=80, command=self.speed_up_video).pack(side="left", padx=10)
        # N√∫t Ch·ª•p ·∫¢nh
        ctk.CTkButton(self.video_controls_frame, text="üì∑ L∆∞u ·∫¢nh", width=100, fg_color="#00ADB5", command=self.save_snapshot).pack(side="right", padx=10)
        
        self.lbl_speed = ctk.CTkLabel(self.video_controls_frame, text="Speed: 1x")
        self.lbl_speed.pack(side="left", padx=10)

        # --- 4. B·∫¢NG ƒê√ÅNH GI√Å (STATS PANEL) ---
        self.stats_panel = ctk.CTkFrame(parent, height=120, fg_color=("white", "#2B2B2B"), corner_radius=10)
        self.stats_panel.grid(row=2, column=0, columnspan=2, sticky="ew", padx=5, pady=5)
        self.stats_panel.grid_columnconfigure(1, weight=1)

        # C·ªôt 1: T√™n t∆∞ th·∫ø
        self.lbl_pose_name = ctk.CTkLabel(self.stats_panel, text="---", font=("Arial", 28, "bold"), text_color="#E63946")
        self.lbl_pose_name.grid(row=0, column=0, rowspan=2, padx=30, pady=10)

        # C·ªôt 2: Feedback
        ctk.CTkLabel(self.stats_panel, text="ƒê√°nh gi√° chi ti·∫øt:", font=("Arial", 12, "bold")).grid(row=0, column=1, sticky="w", padx=10, pady=(10,0))
        self.lbl_feedback = ctk.CTkLabel(self.stats_panel, text="Ch∆∞a c√≥ d·ªØ li·ªáu ph√¢n t√≠ch.", text_color="orange", anchor="w", justify="left")
        self.lbl_feedback.grid(row=1, column=1, sticky="w", padx=10, pady=(0,10))

        # C·ªôt 3: Confidence Score
        self.frame_score = ctk.CTkFrame(self.stats_panel, fg_color="transparent")
        self.frame_score.grid(row=0, column=2, rowspan=2, padx=30)
        
        ctk.CTkLabel(self.frame_score, text="ƒê·ªô ch√≠nh x√°c").pack()
        self.lbl_conf_val = ctk.CTkLabel(self.frame_score, text="0%", font=("Arial", 20, "bold"), text_color="#00ADB5")
        self.lbl_conf_val.pack()
        self.progress_conf = ctk.CTkProgressBar(self.frame_score, orientation="horizontal", width=150, height=10)
        self.progress_conf.set(0)
        self.progress_conf.pack(pady=5)

        # --- 5. GALLERY (Ch·ªâ hi·ªán ·ªü ch·∫ø ƒë·ªô ·∫£nh) ---
        self.gallery_frame = ctk.CTkScrollableFrame(parent, height=80, orientation="horizontal", label_text="·∫¢nh M·∫´u")
        self.gallery_frame.grid(row=3, column=0, columnspan=2, sticky="ew", padx=5, pady=5)

        # Bind resize
        self.lbl_img_input.bind("<Configure>", self.on_frame_configure)
        self.lbl_img_result.bind("<Configure>", self.on_frame_configure)

    # --- LOGIC CHUY·ªÇN ƒê·ªîI CH·∫æ ƒê·ªò & LAYOUT ---
    def switch_to_image_mode(self):
        self.is_video_mode = False
        self.stop_video()
        
        # 1. Kh√¥i ph·ª•c Layout ·∫¢nh: 2 c·ªôt
        self.frame_input.grid(row=0, column=0, sticky="nsew") # Hi·ªán khung Input
        self.frame_output.grid(row=0, column=1, columnspan=1, sticky="nsew") # Khung Output v·ªÅ c·ªôt 1
        
        # 2. ·∫®n Video Controls
        self.video_controls_frame.grid_remove()
        
        # 3. UI Update kh√°c
        self.btn_mode_image.configure(fg_color="#00ADB5")
        self.btn_mode_video.configure(fg_color="transparent")
        self.btn_upload.configure(text="üìÇ T·∫£i ·∫¢nh L√™n")
        self.gallery_frame.grid() # Hi·ªán gallery
        self.lbl_pose_name.configure(text="---")
        self.progress_conf.set(0)
        self.lbl_conf_val.configure(text="0%")
        self.lbl_output_title.configure(text="K·∫æT QU·∫¢ AI")

    def switch_to_video_mode(self):
        self.is_video_mode = True
        self.stop_video()
        
        # 1. Thay ƒë·ªïi Layout Video: 1 khung l·ªõn
        self.frame_input.grid_forget() # ·∫®n khung Input
        self.frame_output.grid(row=0, column=0, columnspan=2, sticky="nsew") # Khung Output tr√†n 2 c·ªôt
        
        # 2. Hi·ªán Video Controls
        self.video_controls_frame.grid(row=1, column=0, columnspan=2, sticky="ew", pady=(0, 10))
        
        # 3. UI Update kh√°c
        self.btn_mode_image.configure(fg_color="transparent")
        self.btn_mode_video.configure(fg_color="#E63946")
        self.btn_upload.configure(text="üìÇ T·∫£i Video L√™n")
        self.gallery_frame.grid_remove() # ·∫®n gallery
        self.lbl_pose_name.configure(text="---")
        self.progress_conf.set(0)
        self.lbl_conf_val.configure(text="0%")
        self.lbl_output_title.configure(text="PH√ÇN T√çCH VIDEO")

    # --- VIDEO CONTROLS LOGIC ---
    def toggle_pause(self):
        if not self.video_running: return
        self.is_paused = not self.is_paused
        if self.is_paused:
            self.btn_pause.configure(text="‚ñ∂ Ti·∫øp T·ª•c", fg_color="#00C853")
        else:
            self.btn_pause.configure(text="‚è∏ T·∫°m D·ª´ng", fg_color="#E63946")
            self.update_video_frame() # G·ªçi l·∫°i loop n·∫øu ƒëang d·ª´ng

    def slow_down_video(self):
        self.video_delay = min(500, self.video_delay + 20) # TƒÉng delay = ch·∫≠m l·∫°i
        self.update_speed_label()

    def speed_up_video(self):
        self.video_delay = max(5, self.video_delay - 20) # Gi·∫£m delay = nhanh h∆°n
        self.update_speed_label()

    def update_speed_label(self):
        # 30ms chu·∫©n l√† 1x.
        speed_x = round(30 / self.video_delay, 1)
        self.lbl_speed.configure(text=f"Speed: {speed_x}x")

    def save_snapshot(self):
        if self.current_frame_cv is None:
            messagebox.showerror("L·ªói", "Kh√¥ng c√≥ khung h√¨nh ƒë·ªÉ l∆∞u!")
            return
            
        # T·ª± ƒë·ªông t·∫°o t√™n file theo th·ªùi gian
        filename = f"snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
        save_path = os.path.join(os.getcwd(), filename)
        
        try:
            # Save frame ƒëang c√≥ (ƒë√£ v·∫Ω Bounding Box)
            cv2.imwrite(save_path, cv2.cvtColor(self.current_frame_cv, cv2.COLOR_RGB2BGR))
            messagebox.showinfo("Th√†nh c√¥ng", f"ƒê√£ l∆∞u ·∫£nh t·∫°i:\n{save_path}")
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ l∆∞u ·∫£nh: {e}")

    # --- VIDEO FILE LOGIC ---
    def start_video(self, file_path):
        if self.video_running: return
        
        self.cap = cv2.VideoCapture(file_path)
        if not self.cap.isOpened():
            messagebox.showerror("L·ªói", "Kh√¥ng th·ªÉ m·ªü file Video n√†y!")
            return
            
        self.video_running = True
        self.is_paused = False
        self.video_delay = 30 # Reset t·ªëc ƒë·ªô
        self.update_speed_label()
        self.btn_pause.configure(text="‚è∏ T·∫°m D·ª´ng", fg_color="#E63946")
        self.lbl_feedback.configure(text="ƒêang ph√¢n t√≠ch Video...")
        
        # Ch·∫°y loop c·∫≠p nh·∫≠t frame
        self.update_video_frame()

    def stop_video(self):
        self.video_running = False
        if self.cap and self.cap.isOpened():
            self.cap.release()
        self.lbl_img_input.configure(image=None)
        self.lbl_img_result.configure(image=None)

    def update_video_frame(self):
        if not self.video_running or not self.is_video_mode:
            return
            
        if self.is_paused:
            return # D·ª´ng g·ªçi ƒë·ªá quy n·∫øu pause

        ret, frame = self.cap.read()
        if ret:
            # X·ª≠ l√Ω AI ngay tr√™n frame n√†y
            self.process_frame_live(frame)
            
            # L·∫∑p l·∫°i sau video_delay ms
            self.after(self.video_delay, self.update_video_frame)
        else:
            # H·∫øt video -> Loop l·∫°i t·ª´ ƒë·∫ßu ho·∫∑c d·ª´ng? ·ªû ƒë√¢y m√¨nh d·ª´ng.
            self.stop_video()
            self.lbl_feedback.configure(text="ƒê√£ ho√†n th√†nh ph√¢n t√≠ch video.")
            messagebox.showinfo("Ho√†n t·∫•t", "ƒê√£ ch·∫°y h·∫øt video.")

    def process_frame_live(self, frame_cv):
        """X·ª≠ l√Ω AI th·ªùi gian th·ª±c cho t·ª´ng frame Video"""
        try:
            if not MODEL_LOADED:
                # N·∫øu kh√¥ng c√≥ model th√¨ hi·ªÉn th·ªã frame g·ªëc lu√¥n
                img_rgb = cv2.cvtColor(frame_cv, cv2.COLOR_BGR2RGB)
                self.current_frame_cv = img_rgb # L∆∞u ƒë·ªÉ ch·ª•p ·∫£nh
                pil_result = Image.fromarray(img_rgb)
                self.display_image_on_label(pil_result, self.lbl_img_result)
                return

            # 1. AI Detection & Classification
            result = self.detection_model(frame_cv)
            keypoints = self.detection_model.get_xy_keypoint(result)

            if keypoints is None or result.boxes is None or len(result.boxes) == 0:
                self.lbl_pose_name.configure(text="NO POSE", text_color="gray")
                # Hi·ªÉn th·ªã frame g·ªëc n·∫øu kh√¥ng th·∫•y ng∆∞·ªùi
                img_rgb = cv2.cvtColor(frame_cv, cv2.COLOR_BGR2RGB)
                self.current_frame_cv = img_rgb
                pil_result = Image.fromarray(img_rgb)
                self.display_image_on_label(pil_result, self.lbl_img_result)
                return

            input_classification = keypoints[10:]
            pose_label = self.classification_model(input_classification)

            # 2. Logic ƒê√°nh gi√°
            simulated_score = random.uniform(0.85, 0.99)
            feedback_text = self.get_ai_feedback(pose_label)
            
            # 3. V·∫Ω Skeleton & Visualization
            image_draw = result.plot(boxes=False)
            x_min, y_min, x_max, y_max = result.boxes.xyxy[0].cpu().numpy().astype(int)
            cv2.rectangle(image_draw, (x_min, y_min), (x_max, y_max), (0, 255, 0), 4)

            image_draw_rgb = cv2.cvtColor(image_draw, cv2.COLOR_BGR2RGB)
            self.current_frame_cv = image_draw_rgb # L∆∞u frame ƒë√£ v·∫Ω ƒë·ªÉ ch·ª•p ·∫£nh
            pil_result = Image.fromarray(image_draw_rgb)

            # 4. C·∫≠p nh·∫≠t UI K·∫øt qu·∫£
            self.display_image_on_label(pil_result, self.lbl_img_result)
            self.update_ui_result(pil_result, pose_label, simulated_score, feedback_text)

        except Exception as e:
            print(f"Video Error: {e}")

    def get_ai_feedback(self, label):
        """H√†m l·∫•y feedback d·ª±a tr√™n nh√£n t∆∞ th·∫ø"""
        feedback_db = {
            "downdog": "L∆∞ng th·∫≥ng, g√≥t ch√¢n ch·∫°m s√†n. H√≠t th·ªü s√¢u.",
            "warrior2": "ƒê·∫ßu g·ªëi vu√¥ng g√≥c, m·∫Øt nh√¨n theo tay. Si·∫øt c∆° ƒë√πi.",
            "tree": "M·∫Øt t·∫≠p trung m·ªôt ƒëi·ªÉm. Gi·ªØ thƒÉng b·∫±ng t·ªët.",
            "plank": "Si·∫øt c∆° b·ª•ng, l∆∞ng kh√¥ng v√µng. Gi·ªØ th·∫≥ng ng∆∞·ªùi.",
            "cobra": "M·ªü r·ªông ng·ª±c, th·∫£ l·ªèng vai. ƒê·ª´ng ng·ª≠a c·ªï qu√° m·ª©c."
        }
        for key, text in feedback_db.items():
            if key in label.lower():
                return text
        return "T∆∞ th·∫ø ·ªïn ƒë·ªãnh. H√£y duy tr√¨ nh·ªãp th·ªü ƒë·ªÅu."

    def update_ui_result(self, pil_img, label, score, feedback):
        """C·∫≠p nh·∫≠t giao di·ªán k·∫øt qu·∫£ v√† thanh ƒëi·ªÉm s·ªë"""
        # C·∫≠p nh·∫≠t th√¥ng s·ªë
        self.lbl_pose_name.configure(text=label.upper(), text_color="#00ADB5")
        
        # C·∫≠p nh·∫≠t thanh Progress Bar v√† %
        self.progress_conf.set(score)
        self.lbl_conf_val.configure(text=f"{int(score*100)}%")
        
        if score > 0.9: self.progress_conf.configure(progress_color="#00E676")
        elif score > 0.7: self.progress_conf.configure(progress_color="#FFEA00")
        else: self.progress_conf.configure(progress_color="#FF3D00")

        self.lbl_feedback.configure(text=feedback)

    # --- IMAGE LOGIC & DIALOG ---
    def open_file_dialog(self):
        if self.is_video_mode:
            # Ch·ªçn Video
            file_path = filedialog.askopenfilename(filetypes=[("Video Files", "*.mp4;*.avi;*.mov;*.mkv")])
            if file_path:
                self.start_video(file_path)
        else:
            # Ch·ªçn ·∫¢nh
            file_path = filedialog.askopenfilename(filetypes=[("Image Files", "*.jpg;*.jpeg;*.png")])
            if file_path:
                self.current_image = file_path
                threading.Thread(target=self.process_image_logic, args=(file_path,)).start()

    def process_image_logic(self, img_path):
        try:
            pil_image = Image.open(img_path).convert("RGB")
            self.current_pil_image = pil_image
            
            self.after(0, lambda: self.display_image_on_label(pil_image, self.lbl_img_input))
            self.after(0, lambda: self.lbl_img_result.configure(text="ƒêang ph√¢n t√≠ch...", image=None))

            if not MODEL_LOADED: return

            image_cv = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            result = self.detection_model(image_cv)
            keypoints = self.detection_model.get_xy_keypoint(result)

            if keypoints is None or result.boxes is None or len(result.boxes) == 0:
                self.after(0, lambda: self.lbl_img_result.configure(text="Kh√¥ng t√¨m th·∫•y ng∆∞·ªùi"))
                return

            input_classification = keypoints[10:]
            pose_label = self.classification_model(input_classification)
            
            # Logic ƒë√°nh gi√°
            simulated_score = random.uniform(0.85, 0.99)
            feedback_text = self.get_ai_feedback(pose_label)

            image_draw = result.plot(boxes=False)
            x_min, y_min, x_max, y_max = result.boxes.xyxy[0].cpu().numpy().astype(int)
            cv2.rectangle(image_draw, (x_min, y_min), (x_max, y_max), (0, 255, 0), 4)
            
            image_draw_rgb = cv2.cvtColor(image_draw, cv2.COLOR_BGR2RGB)
            pil_result = Image.fromarray(image_draw_rgb)
            self.current_result_image = pil_result

            self.after(0, lambda: self.display_image_on_label(pil_result, self.lbl_img_result))
            self.after(0, lambda: self.update_ui_result(pil_result, pose_label, simulated_score, feedback_text))

        except Exception as e:
            print(f"Image Error: {e}")

    # --- UTILS ---
    def display_image_on_label(self, pil_img, ctk_label):
        w_widget = ctk_label.winfo_width()
        h_widget = ctk_label.winfo_height()
        if w_widget < 10 or h_widget < 10: return

        img_ratio = pil_img.width / pil_img.height
        widget_ratio = w_widget / h_widget

        if widget_ratio > img_ratio:
            display_h = h_widget
            display_w = int(h_widget * img_ratio)
        else:
            display_w = w_widget
            display_h = int(w_widget / img_ratio)

        ctk_img = ctk.CTkImage(light_image=pil_img, dark_image=pil_img, size=(display_w, display_h))
        ctk_label.configure(image=ctk_img, text="")
        ctk_label.image = ctk_img

    def on_frame_configure(self, event):
        if not self.is_video_mode:
            if self.current_pil_image: self.display_image_on_label(self.current_pil_image, self.lbl_img_input)
            if self.current_result_image: self.display_image_on_label(self.current_result_image, self.lbl_img_result)
        else:
            # Trong ch·∫ø ƒë·ªô video, n·∫øu paused v√† c√≥ frame hi·ªán t·∫°i th√¨ redraw khi resize
            if self.is_paused and self.current_frame_cv is not None:
                 pil_img = Image.fromarray(self.current_frame_cv)
                 self.display_image_on_label(pil_img, self.lbl_img_result)

    def change_appearance_mode_event(self, new_appearance_mode: str):
        ctk.set_appearance_mode(new_appearance_mode)
    
    def load_sample_images_ui(self):
        images = glob.glob("./images/*.jpeg") + glob.glob("./images/*.jpg")
        for i, img_path in enumerate(images[:10]):
            try:
                img = Image.open(img_path)
                ctk_thumb = ctk.CTkImage(img, size=(80, 80))
                btn = ctk.CTkButton(self.gallery_frame, image=ctk_thumb, text="", width=90, height=90,
                                    fg_color="transparent", border_width=2, border_color="gray",
                                    command=lambda p=img_path: self.open_file_dialog_manual(p))
                btn.grid(row=0, column=i, padx=5, pady=5)
            except: pass
            
    def open_file_dialog_manual(self, path):
        self.current_image = path
        if self.is_video_mode: self.switch_to_image_mode()
        threading.Thread(target=self.process_image_logic, args=(path,)).start()

if __name__ == "__main__":
    app = YogaApp()
    app.mainloop()