import tkinter as tk
from tkinter import filedialog, messagebox
import customtkinter as ctk
from PIL import Image, ImageTk, ImageOps
import cv2
import numpy as np
import os
import glob
import threading
import time
from datetime import datetime
import sys
from pathlib import Path
import queue  # üöÄ For async video processing

# --- C·∫§U H√åNH GIAO DI·ªÜN & X·ª¨ L√ù ---
ctk.set_appearance_mode("Dark")
ctk.set_default_color_theme("dark-blue")

APP_NAME = "YOLOv8 Yoga Pose Assessment - HCMUTE Group 18"
WINDOW_WIDTH = 1366
WINDOW_HEIGHT = 768

# K√≠ch th∆∞·ªõc chu·∫©n ƒë·ªÉ x·ª≠ l√Ω AI (T·∫•t c·∫£ ·∫£nh/video s·∫Ω ƒë∆∞·ª£c ƒë∆∞a v·ªÅ size n√†y tr∆∞·ªõc khi v·∫Ω)
# üöÄ OPTIMIZED: Gi·∫£m t·ª´ 1280x720 xu·ªëng 960x540 ƒë·ªÉ tƒÉng FPS
PROCESS_WIDTH = 960
PROCESS_HEIGHT = 540

# --- IMPORT MODULES T·ª™ SRC ---
sys.path.insert(0, str(Path(__file__).parent))

try:
    from src.detection.pose_detector import PoseDetector
    from src.recognition.pose_recognizer import PoseRecognizer
    from src.evaluation.pose_evaluator import PoseEvaluator
    from src.visualization.skeleton_drawer import SkeletonDrawer
    from src.visualization.overlay_ui import OverlayUI
    MODEL_LOADED = True
except ImportError as e:
    MODEL_LOADED = False
    print(f"‚ö†Ô∏è L·ªñI IMPORT: {e}")
    print("Vui l√≤ng ki·ªÉm tra c·∫•u tr√∫c th∆∞ m·ª•c 'src/' v√† 'config/'.")

class YogaApp(ctk.CTk):
    def __init__(self):
        super().__init__()

        # Setup C·ª≠a s·ªï ch√≠nh
        self.title(APP_NAME)
        
        # C·∫•u h√¨nh k√≠ch th∆∞·ªõc c∆° b·∫£n
        screen_width = self.winfo_screenwidth()
        screen_height = self.winfo_screenheight()
        
        # Thi·∫øt l·∫≠p geometry ban ƒë·∫ßu (s·∫Ω ƒë∆∞·ª£c override b·ªüi state zoomed b√™n d∆∞·ªõi)
        x_cordinate = int((screen_width / 2) - (WINDOW_WIDTH / 2))
        y_cordinate = int((screen_height / 2) - (WINDOW_HEIGHT / 2))
        self.geometry(f"{WINDOW_WIDTH}x{WINDOW_HEIGHT}+{x_cordinate}+{y_cordinate}")
        self.minsize(1024, 600)

        # --- T·ª∞ ƒê·ªòNG FULL M√ÄN H√åNH (MAXIMIZED) ---
        # Linux kh√¥ng h·ªó tr·ª£ 'zoomed', d√πng attributes() ƒë·ªÉ maximize
        try:
            # Th·ª≠ d√πng attributes (Linux-friendly)
            self.attributes('-zoomed', True)
        except Exception:
            try:
                # Fallback: Windows/Mac style
                self.state('zoomed')
            except Exception:
                # Fallback cu·ªëi: Manual geometry
                self.geometry(f"{screen_width}x{screen_height}+0+0")
        
        # --- KH·ªûI T·∫†O C√ÅC MODULE AI ---
        self.detector = None
        self.recognizer = None
        self.evaluator = None
        self.drawer = None
        self.overlay = None
        
        # Thread loading model
        self.after(100, self.init_models)

        # Layout Ch√≠nh
        self.grid_columnconfigure(1, weight=1)
        self.grid_rowconfigure(0, weight=1)

        # 1. SIDEBAR (Menu tr√°i)
        self.create_sidebar()

        # 2. TABVIEW (Khu v·ª±c ch√≠nh)
        self.create_main_view()

        # Bi·∫øn tr·∫°ng th√°i
        self.current_image_path = None
        self.current_pil_image = None
        self.current_result_image = None # L∆∞u ·∫£nh k·∫øt qu·∫£ PIL (Full size ƒë√£ x·ª≠ l√Ω)
        self.current_frame_processed = None # L∆∞u frame k·∫øt qu·∫£ (OpenCV format)
        
        # Bi·∫øn cho Video Control
        self.is_video_mode = False
        self.cap = None
        self.video_running = False
        self.is_paused = False
        self.video_delay = 30
        self.current_pose_name = "Unknown"  # Track current pose for snapshot naming
        self.current_score = 0  # Track current score for snapshot naming
        
        # üöÄ ASYNC VIDEO PROCESSING: Producer-Consumer Architecture
        self.frame_queue = queue.Queue(maxsize=5)  # Buffer 5 frames
        self.processing_thread = None
        self.frame_counter = 0
        self.process_every_n_frames = 1  # X·ª≠ l√Ω m·ªói N frame (1=all, 2=every other)
        
        # ‚å®Ô∏è Keyboard shortcuts
        self.bind_all("<space>", lambda e: self.toggle_pause())
        self.bind_all("<KeyPress-s>", lambda e: self.save_snapshot())
        self.bind_all("<KeyPress-S>", lambda e: self.save_snapshot())
        
        # Load sample images ban ƒë·∫ßu
        self.after(1000, self.load_sample_images_ui)

    def init_models(self):
        """Kh·ªüi t·∫°o c√°c class x·ª≠ l√Ω t·ª´ file src"""
        if MODEL_LOADED:
            try:
                print("‚è≥ ƒêang t·∫£i models...")
                yolo_path = "models/yolov8m-pose.pt"
                clf_path = "models/pose_classification.pth"
                
                if not os.path.exists(yolo_path):
                    yolo_path = "yolov8m-pose.pt" 
                
                # Enable GPU for maximum performance
                self.detector = PoseDetector(
                    model_path=yolo_path, 
                    confidence_threshold=0.5,
                    use_gpu=True  # üöÄ GPU Acceleration enabled
                )
                self.recognizer = PoseRecognizer(model_path=clf_path)
                self.evaluator = PoseEvaluator()
                self.drawer = SkeletonDrawer()
                self.overlay = OverlayUI()
                
                print("‚úÖ ƒê√£ t·∫£i xong to√†n b·ªô Models & Modules.")
                self.lbl_feedback.configure(text="H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!", text_color="#00E676")
            except Exception as e:
                print(f"‚ùå L·ªói kh·ªüi t·∫°o Model: {e}")
                self.lbl_feedback.configure(text="L·ªói t·∫£i Model AI", text_color="red")
                # Kh√¥ng hi·ªÉn th·ªã popup l·ªói ngay l·∫≠p t·ª©c ƒë·ªÉ tr√°nh block UI khi kh·ªüi ƒë·ªông
                print(f"Chi ti·∫øt l·ªói: {e}")

    def create_sidebar(self):
        self.sidebar_frame = ctk.CTkFrame(self, width=300, corner_radius=0)
        self.sidebar_frame.grid(row=0, column=0, sticky="nsew")
        self.sidebar_frame.grid_rowconfigure(7, weight=1)

        # --- 1. LOGO TR∆Ø·ªúNG HCMUTE (Row 0) ---
        self.logo_image = None
        try:
            # ƒê·∫£m b·∫£o file 'logo.png' n·∫±m c√πng th∆∞ m·ª•c
            img_path = "logo.png" 
            if os.path.exists(img_path):
                img = Image.open(img_path)
                # Resize logo cho v·ª´a khung (v√≠ d·ª•: 150x150)
                self.logo_image = ctk.CTkImage(light_image=img, dark_image=img, size=(160, 160))
            else:
                print("Kh√¥ng t√¨m th·∫•y file logo 'logo.png'.")
        except Exception as e:
            print(f"L·ªói load logo: {e}")

        if self.logo_image:
            self.lbl_logo_img = ctk.CTkLabel(self.sidebar_frame, image=self.logo_image, text="")
            self.lbl_logo_img.grid(row=0, column=0, padx=20, pady=(20, 5))
        
        # --- 2. T√äN ƒê·ªÄ T√ÄI (Row 1 - N·∫±m d∆∞·ªõi logo) ---
        # S·ª≠ d·ª•ng wraplength ƒë·ªÉ t·ª± ƒë·ªông xu·ªëng d√≤ng
        title_text = "üßò ·ª®ng d·ª•ng YOLOv8 tr√≠ch xu·∫•t khung x∆∞∆°ng, nh·∫≠n d·∫°ng & ƒë√°nh gi√° Yoga"
        self.lbl_project_title = ctk.CTkLabel(self.sidebar_frame, 
                                            text=title_text,
                                            font=ctk.CTkFont(size=16, weight="bold"),
                                            wraplength=240, # T·ª± ƒë·ªông xu·ªëng d√≤ng n·∫øu d√†i qu√° 240px
                                            justify="center")
        self.lbl_project_title.grid(row=1, column=0, padx=10, pady=(5, 20))
        
        # --- 3. MODE CONTROL (Row 2) ---
        ctk.CTkLabel(self.sidebar_frame, text="CH·∫æ ƒê·ªò HO·∫†T ƒê·ªòNG", font=("Arial", 12, "bold"), text_color="gray").grid(row=2, column=0, pady=(10, 5))
        
        # --- 4. BUTTONS (Row 3, 4, 5) ---
        self.btn_mode_image = ctk.CTkButton(self.sidebar_frame, text="üì∑ Ph√¢n t√≠ch ·∫¢nh", 
                                          fg_color="#00ADB5",
                                          command=self.switch_to_image_mode)
        self.btn_mode_image.grid(row=3, column=0, padx=20, pady=10)

        self.btn_mode_video = ctk.CTkButton(self.sidebar_frame, text="üé• Ph√¢n t√≠ch Video", 
                                          fg_color="transparent", border_width=2, border_color="#E63946", text_color="#E63946",
                                          command=self.switch_to_video_mode)
        self.btn_mode_video.grid(row=4, column=0, padx=20, pady=10)

        self.btn_upload = ctk.CTkButton(self.sidebar_frame, text="üìÇ T·∫£i File L√™n", 
                                      command=self.open_file_dialog,
                                      fg_color="#333", hover_color="#444")
        self.btn_upload.grid(row=5, column=0, padx=20, pady=20)

        # --- 5. INFO BOX (Row 6) ---
        self.info_box = ctk.CTkTextbox(self.sidebar_frame, height=250, fg_color="transparent", text_color="gray", font=("Arial", 12))
        
        info_text = (
            "NH√ìM 18 - HCMUTE:\n"
            "1. Mai H·ªìng H·∫£i - MSSV: 22133014\n"
            "2. Nguy·ªÖn T·∫•n H√πng - MSSV: 22133027\n"
            "3. Nguy·ªÖn Ng·ªçc Hi·∫øu H·∫£o - MSSV: 22133015\n\n\n"
            "H∆Ø·ªöNG D·∫™N:\n"
            "- Ch·ªçn ·∫¢nh/Video ƒë·ªÉ ph√¢n t√≠ch.\n"
            "- H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông resize ·∫£nh v·ªÅ chu·∫©n HD ƒë·ªÉ ph√¢n t√≠ch.\n"
            "- AI s·∫Ω ch·∫•m ƒëi·ªÉm k·ªπ thu·∫≠t.\n"
            "- K·∫øt qu·∫£ hi·ªÉn th·ªã b√™n tr√™n m√†n h√¨nh."
        )
        
        self.info_box.insert("0.0", info_text)
        self.info_box.configure(state="disabled")
        self.info_box.grid(row=6, column=0, padx=20, pady=5)

        # Settings (Row 8 - ƒë·∫©y xu·ªëng d∆∞·ªõi c√πng)
        self.appearance_mode_menu = ctk.CTkOptionMenu(self.sidebar_frame, values=["Dark", "Light", "System"],
                                                    command=self.change_appearance_mode_event)
        self.appearance_mode_menu.grid(row=8, column=0, padx=20, pady=(0, 100))

    def create_main_view(self):
        # --- C·∫¨P NH·∫¨T: X√≥a TabView, d√πng Frame tr·ª±c ti·∫øp ƒë·ªÉ t·ªëi ƒëa kh√¥ng gian ---
        self.main_view = ctk.CTkFrame(self, fg_color="transparent")
        self.main_view.grid(row=0, column=1, sticky="nsew", padx=10, pady=10)
        
        self.setup_dashboard_view(self.main_view)

    def setup_dashboard_view(self, parent):
        parent.grid_columnconfigure((0, 1), weight=1, uniform="equal_cols")
        parent.grid_rowconfigure(0, weight=1) # ·∫¢nh s·∫Ω chi·∫øm ph·∫ßn l·ªõn kh√¥ng gian
        parent.grid_rowconfigure(1, weight=0) # Controls row
        parent.grid_rowconfigure(2, weight=0) 
        parent.grid_rowconfigure(3, weight=0) 

        # --- 1. KHUNG INPUT ---
        self.frame_input = ctk.CTkFrame(parent, fg_color=("gray90", "#212121"))
        # Gi·∫£m padding ƒë·ªÉ khung to h∆°n
        self.frame_input.grid(row=0, column=0, sticky="nsew", padx=2, pady=2)
        self.frame_input.grid_columnconfigure(0, weight=1)
        self.frame_input.grid_rowconfigure(1, weight=1)

        self.lbl_input_title = ctk.CTkLabel(self.frame_input, text="·∫¢NH G·ªêC", font=("Arial", 14, "bold"), text_color="gray")
        self.lbl_input_title.grid(row=0, column=0, pady=2)
        
        self.lbl_img_input = ctk.CTkLabel(self.frame_input, text="S·∫µn s√†ng...", corner_radius=0)
        self.lbl_img_input.grid(row=1, column=0, sticky="nsew", padx=2, pady=2)

        # --- 2. KHUNG OUTPUT ---
        self.frame_output = ctk.CTkFrame(parent, fg_color=("gray90", "#212121"))
        # Gi·∫£m padding ƒë·ªÉ khung to h∆°n
        self.frame_output.grid(row=0, column=1, sticky="nsew", padx=2, pady=2)
        self.frame_output.grid_columnconfigure(0, weight=1)
        self.frame_output.grid_rowconfigure(1, weight=1)

        self.lbl_output_title = ctk.CTkLabel(self.frame_output, text="K·∫æT QU·∫¢ AI", font=("Arial", 14, "bold"), text_color="#00ADB5")
        self.lbl_output_title.grid(row=0, column=0, pady=2)
        
        self.lbl_img_result = ctk.CTkLabel(self.frame_output, text="K·∫øt qu·∫£ hi·ªÉn th·ªã t·∫°i ƒë√¢y", corner_radius=0)
        self.lbl_img_result.grid(row=1, column=0, sticky="nsew", padx=2, pady=2)

        # --- 3a. VIDEO CONTROLS ---
        self.video_controls_frame = ctk.CTkFrame(parent, height=50, fg_color="transparent")
        self.video_controls_frame.grid_remove() # ·∫®n m·∫∑c ƒë·ªãnh
        
        # Pause/Resume button
        self.btn_pause = ctk.CTkButton(self.video_controls_frame, text="‚è∏ T·∫°m D·ª´ng", width=120, fg_color="#E63946", command=self.toggle_pause)
        self.btn_pause.pack(side="left", padx=10)
        
        # Snapshot button
        ctk.CTkButton(self.video_controls_frame, text="üì∑ L∆∞u ·∫¢nh", width=120, fg_color="#00ADB5", command=self.save_snapshot).pack(side="right", padx=10)

        # --- 3b. IMAGE CONTROLS (N√∫t l∆∞u ·∫£nh) ---
        self.image_controls_frame = ctk.CTkFrame(parent, height=50, fg_color="transparent")
        self.image_controls_frame.grid(row=1, column=0, columnspan=2, sticky="ew", pady=(0, 10)) # M·∫∑c ƒë·ªãnh hi·ªán
        
        self.btn_save_image = ctk.CTkButton(self.image_controls_frame, text="üíæ L∆∞u K·∫øt Qu·∫£", 
                                          width=150, height=35,
                                          fg_color="#00ADB5", hover_color="#007d85",
                                          font=("Arial", 13, "bold"),
                                          command=self.save_image_result)
        self.btn_save_image.pack(pady=5)

        # --- 4. STATS PANEL ---
        self.stats_panel = ctk.CTkFrame(parent, height=120, fg_color=("white", "#2B2B2B"), corner_radius=10)
        self.stats_panel.grid(row=2, column=0, columnspan=2, sticky="ew", padx=5, pady=5)
        self.stats_panel.grid_columnconfigure(1, weight=1)

        self.lbl_pose_name = ctk.CTkLabel(self.stats_panel, text="---", font=("Arial", 28, "bold"), text_color="#E63946")
        self.lbl_pose_name.grid(row=0, column=0, rowspan=2, padx=30, pady=10)

        ctk.CTkLabel(self.stats_panel, text="ƒê√°nh gi√° chi ti·∫øt:", font=("Arial", 12, "bold")).grid(row=0, column=1, sticky="w", padx=10, pady=(10,0))
        self.lbl_feedback = ctk.CTkLabel(self.stats_panel, text="Ch∆∞a c√≥ d·ªØ li·ªáu ph√¢n t√≠ch.", text_color="orange", anchor="w", justify="left")
        self.lbl_feedback.grid(row=1, column=1, sticky="w", padx=10, pady=(0,10))

        self.frame_score = ctk.CTkFrame(self.stats_panel, fg_color="transparent")
        self.frame_score.grid(row=0, column=2, rowspan=2, padx=30)
        
        ctk.CTkLabel(self.frame_score, text="ƒê·ªô ch√≠nh x√°c").pack()
        self.lbl_conf_val = ctk.CTkLabel(self.frame_score, text="0%", font=("Arial", 20, "bold"), text_color="#00ADB5")
        self.lbl_conf_val.pack()
        self.progress_conf = ctk.CTkProgressBar(self.frame_score, orientation="horizontal", width=150, height=10)
        self.progress_conf.set(0)
        self.progress_conf.pack(pady=5)

        # --- 5. GALLERY ---
        self.gallery_frame = ctk.CTkScrollableFrame(parent, height=80, orientation="horizontal", label_text="·∫¢nh M·∫´u")
        self.gallery_frame.grid(row=3, column=0, columnspan=2, sticky="ew", padx=5, pady=5)

        # Bind event resize ƒë·ªÉ v·∫Ω l·∫°i ·∫£nh cho fit khung
        self.lbl_img_input.bind("<Configure>", self.on_frame_configure)
        self.lbl_img_result.bind("<Configure>", self.on_frame_configure)

    # --- LOGIC CHUY·ªÇN ƒê·ªîI CH·∫æ ƒê·ªò ---
    def switch_to_image_mode(self):
        self.is_video_mode = False
        self.stop_video()
        
        
        # Clear display when switching modes
        self.lbl_img_result.configure(image=None, text="")
        
        self.frame_input.grid(row=0, column=0, sticky="nsew")
        self.frame_output.grid(row=0, column=1, columnspan=1, sticky="nsew")
        
        self.video_controls_frame.grid_remove()
        self.image_controls_frame.grid(row=1, column=0, columnspan=2, sticky="ew", pady=(0, 10)) 
        
        self.btn_mode_image.configure(fg_color="#00ADB5")
        self.btn_mode_video.configure(fg_color="transparent")
        self.btn_upload.configure(text="üìÇ T·∫£i ·∫¢nh L√™n")
        self.gallery_frame.grid() 
        self.lbl_output_title.configure(text="K·∫æT QU·∫¢ AI")
        self.reset_stats()

    def switch_to_video_mode(self):
        self.is_video_mode = True
        self.stop_video()
        
        
        # Clear display when switching modes
        self.lbl_img_result.configure(image=None, text="")
        
        self.frame_input.grid_forget()
        self.frame_output.grid(row=0, column=0, columnspan=2, sticky="nsew")
        
        self.image_controls_frame.grid_remove() 
        self.video_controls_frame.grid(row=1, column=0, columnspan=2, sticky="ew", pady=(0, 10))
        
        self.btn_mode_image.configure(fg_color="transparent")
        self.btn_mode_video.configure(fg_color="#E63946")
        self.btn_upload.configure(text="üìÇ T·∫£i Video L√™n")
        self.gallery_frame.grid_remove() 
        self.lbl_output_title.configure(text="PH√ÇN T√çCH VIDEO")
        self.reset_stats()

    def reset_stats(self):
        self.lbl_pose_name.configure(text="---")
        self.progress_conf.set(0)
        self.lbl_conf_val.configure(text="0%")
        self.lbl_feedback.configure(text="ƒêang ch·ªù d·ªØ li·ªáu...")

    # --- VIDEO CONTROLS ---
    def toggle_pause(self):
        """Pause/Resume video playback"""
        if not self.video_running:
            return
        
        self.is_paused = not self.is_paused
        self.btn_pause.configure(
            text="‚ñ∂ Ti·∫øp T·ª•c" if self.is_paused else "‚è∏ T·∫°m D·ª´ng",
            fg_color="#00C853" if self.is_paused else "#E63946"
        )
        
        # Resume display worker if unpaused
        if not self.is_paused:
            self.display_video_worker()

    def save_snapshot(self):
        if self.current_frame_processed is None:
            messagebox.showerror("L·ªói", "Ch∆∞a c√≥ khung h√¨nh ƒë·ªÉ l∆∞u!")
            return
            
        # Create filename with pose name and score
        pose_clean = self.current_pose_name.lower().replace(" ", "_")
        score_str = f"{self.current_score}pct"  # e.g., "95pct"
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{pose_clean}_{score_str}_{timestamp}.jpg"
        if not os.path.exists("snapshots"):
            os.makedirs("snapshots")
            
        save_path = os.path.join("snapshots", filename)
        
        try:
            cv2.imwrite(save_path, self.current_frame_processed)
            messagebox.showinfo("ƒê√£ l∆∞u", f"L∆∞u ·∫£nh th√†nh c√¥ng:\n{filename}")
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ l∆∞u file: {e}")

    # -------------------------------------------------------------------------
    # H√ÄM RESIZE QUAN TR·ªåNG: D√πng chung cho c·∫£ x·ª≠ l√Ω AI v√† Hi·ªÉn th·ªã
    # -------------------------------------------------------------------------
    def resize_image_to_fixed_size(self, image_cv, target_size=(PROCESS_WIDTH, PROCESS_HEIGHT)):
        """
        Resize ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh (target_size) m√† gi·ªØ nguy√™n t·ª∑ l·ªá.
        Ph·∫ßn th·ª´a s·∫Ω ƒë∆∞·ª£c th√™m padding m√†u ƒëen (Letterboxing).
        """
        target_w, target_h = target_size
        h, w = image_cv.shape[:2]
        
        # T√≠nh t·ª∑ l·ªá resize ƒë·ªÉ fit v√†o target_size
        scale = min(target_w/w, target_h/h)
        new_w = int(w * scale)
        new_h = int(h * scale)
        
        # Resize ·∫£nh
        resized = cv2.resize(image_cv, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
        
        # T·∫°o canvas ƒëen (target size)
        canvas = np.zeros((target_h, target_w, 3), dtype=np.uint8)
        
        # T√≠nh to√°n v·ªã tr√≠ paste (center)
        x_offset = (target_w - new_w) // 2
        y_offset = (target_h - new_h) // 2
        
        # Paste ·∫£nh v√†o canvas
        canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
        
        return canvas

    def save_image_result(self):
        """L∆∞u ·∫£nh k·∫øt qu·∫£ v√†o th∆∞ m·ª•c results"""
        if self.current_frame_processed is None:
            messagebox.showerror("L·ªói", "Ch∆∞a c√≥ k·∫øt qu·∫£ ph√¢n t√≠ch ƒë·ªÉ l∆∞u!")
            return
            
        filename = f"result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
        
        # T·∫°o th∆∞ m·ª•c results n·∫øu ch∆∞a c√≥
        if not os.path.exists("results"):
            os.makedirs("results")
            
        save_path = os.path.join("results", filename)
        try:
            # L∆∞u ·∫£nh (ƒë√£ ƒë∆∞·ª£c resize v√† v·∫Ω s·∫µn t·ª´ pipeline x·ª≠ l√Ω)
            cv2.imwrite(save_path, self.current_frame_processed)
            messagebox.showinfo("Th√†nh c√¥ng", f"ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£ t·∫°i:\n{save_path}")
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ l∆∞u file: {e}")

    # --- üöÄ ASYNC VIDEO PROCESSING ---
    def process_video_worker(self):
        """Background thread: Read + Process frames ‚Üí Queue (Producer)"""
        frame_count = 0
        
        while self.video_running:
            # ‚úÖ FIX: Check pause state
            if self.is_paused:
                time.sleep(0.1)  # Sleep when paused
                continue
            
            if self.cap is None or not self.cap.isOpened():
                break
                
            ret, frame = self.cap.read()
            if not ret:
                self.video_running = False
                break
            
            frame_count += 1
            
            # Skip frames if needed
            if frame_count % self.process_every_n_frames != 0:
                continue
            
            try:
                # Resize
                frame_resized = self.resize_image_to_fixed_size(frame, (PROCESS_WIDTH, PROCESS_HEIGHT))
                
                # Process AI (YOLOv8, ML, Drawing) - All on GPU!
                if MODEL_LOADED and self.detector:
                    results = self.detector.predict(frame_resized)
                    kp_norm = self.detector.get_keypoints_normalized(results)
                    kp_abs = self.detector.get_keypoints_absolute(results)
                    
                    if kp_norm and kp_abs:
                        pose_name, confidence = self.recognizer.recognize(kp_norm)
                        score, feedback = self.evaluator.evaluate(pose_name, kp_abs)
                        frame_drawn = self.drawer.draw(frame_resized.copy(), kp_abs, score)
                        frame_final = self.overlay.draw_scoreboard(frame_drawn, pose_name, score, feedback)
                    else:
                        pose_name, score, feedback = "NO POSE", 0, "Kh√¥ng t√¨m th·∫•y ng∆∞·ªùi"
                        frame_final = frame_resized
                else:
                    pose_name, score, feedback = "Loading", 0, "ƒêang t·∫£i..."
                    frame_final = frame_resized
                
                # Put processed frame to queue (non-blocking)
                try:
                    self.frame_queue.put_nowait({
                        'frame': frame_final,
                        'pose': pose_name,
                        'score': score,
                        'feedback': feedback
                    })
                except queue.Full:
                    # Queue full, skip this frame
                    pass
                    
            except Exception as e:
                print(f"Processing error: {e}")
                continue
        
        # Signal end
        try:
            self.frame_queue.put_nowait(None)
        except:
            pass
    
    def display_video_worker(self):
        """UI thread: Get frame from queue ‚Üí Display (Consumer)"""
        if not self.video_running or not self.is_video_mode:
            return
        
        try:
            # Get processed frame from queue (non-blocking)
            data = self.frame_queue.get_nowait()
            
            if data is None:
                # End of video
                self.stop_video()
                self.lbl_feedback.configure(text="K·∫øt th√∫c Video.")
                messagebox.showinfo("Xong", "ƒê√£ ph√¢n t√≠ch xong video.")
                return
            
            # Display frame (FAST!)
            frame_cv = data['frame']
            pose_name = data['pose']
            score = data['score']
            feedback = data['feedback']
            
            # Track current pose and score for snapshots
            self.current_pose_name = pose_name
            self.current_score = score
            
            # Convert + Display
            self.current_frame_processed = frame_cv
            img_rgb = cv2.cvtColor(frame_cv, cv2.COLOR_BGR2RGB)
            pil_result = Image.fromarray(img_rgb)
            self.current_result_image = pil_result
            
            self.display_image_on_label(pil_result, self.lbl_img_result)
            self.update_stats(pose_name, score, feedback)
            
        except queue.Empty:
            # No frame ready, skip this cycle
            pass
        except Exception as e:
            print(f"Display error: {e}")
        
        # Schedule next display update (30 FPS = 33ms)
        if self.video_running and self.is_video_mode:
            self.after(33, self.display_video_worker)
    
    def start_video(self, file_path):
        """Start async video processing"""
        # ‚úÖ FIX: N·∫øu ƒëang c√≥ video (d√π pause), stop n√≥ tr∆∞·ªõc
        if self.video_running:
            self.stop_video()
            # Wait a bit for cleanup
            import time
            time.sleep(0.3)
            
        self.cap = cv2.VideoCapture(file_path)
        if not self.cap.isOpened():
            messagebox.showerror("L·ªói", "Kh√¥ng th·ªÉ m·ªü file Video!")
            return
        
        # Clear queue
        while not self.frame_queue.empty():
            try:
                self.frame_queue.get_nowait()
            except:
                break
        
        self.video_running = True
        self.is_paused = False
        self.btn_pause.configure(text="‚è∏ T·∫°m D·ª´ng", fg_color="#E63946")
        
        # Start processing thread (Background)
        self.processing_thread = threading.Thread(target=self.process_video_worker, daemon=True)
        self.processing_thread.start()
        
        # Start display worker (UI thread)
        self.display_video_worker()

    def stop_video(self):
        """Stop video processing"""
        self.video_running = False
        
        # Wait for processing thread
        if self.processing_thread and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=1.0)
        
        # Release video capture
        if self.cap and self.cap.isOpened():
            self.cap.release()
        
        # Clear queue
        while not self.frame_queue.empty():
            try:
                self.frame_queue.get_nowait()
            except:
                break
        
        self.lbl_img_input.configure(image=None)
        self.lbl_img_result.configure(image=None)
        self.lbl_img_result.configure(text="ƒê√£ d·ª´ng.")

    # (Old update_video_frame removed - replaced by async architecture above)

    def process_image_logic(self, img_path):
        try:
            # 1. Load b·∫±ng PIL ƒë·ªÉ x·ª≠ l√Ω xoay ·∫£nh (EXIF)
            pil_image = Image.open(img_path).convert("RGB")
            pil_image = ImageOps.exif_transpose(pil_image)
            self.current_pil_image = pil_image 
            
            # 2. Hi·ªÉn th·ªã ·∫£nh g·ªëc l√™n UI (resize nh·∫π ƒë·ªÉ hi·ªÉn th·ªã nhanh)
            self.after(0, lambda: self.display_image_on_label(pil_image, self.lbl_img_input))
            self.after(0, lambda: self.lbl_img_result.configure(text="ƒêang ph√¢n t√≠ch AI...", image=None))

            if not MODEL_LOADED: return

            # 3. Chuy·ªÉn sang OpenCV
            frame = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            
            # 4. --- QUAN TR·ªåNG: Resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n TR∆Ø·ªöC khi x·ª≠ l√Ω ---
            # Vi·ªác n√†y ƒë·∫£m b·∫£o b·∫£ng ƒëi·ªÉm v√† khung x∆∞∆°ng lu√¥n c√≥ t·ªâ l·ªá ƒë·∫πp
            frame_resized = self.resize_image_to_fixed_size(frame, (PROCESS_WIDTH, PROCESS_HEIGHT))
            
            # 5. ƒê∆∞a v√†o pipeline x·ª≠ l√Ω
            self.process_and_display(frame_resized, is_video=False)
            
        except Exception as e:
            print(f"L·ªói x·ª≠ l√Ω ·∫£nh: {e}")
            self.after(0, lambda: self.lbl_feedback.configure(text=f"L·ªói: {e}"))

    def process_and_display(self, frame_cv, is_video=False):
        """
        H√†m n√†y nh·∫≠n v√†o frame ƒë√£ ƒë∆∞·ª£c resize chu·∫©n (PROCESS_WIDTH x PROCESS_HEIGHT)
        """
        if not MODEL_LOADED or self.detector is None:
            return

        try:
            # 1. Detect
            results = self.detector.predict(frame_cv)
            kp_norm = self.detector.get_keypoints_normalized(results)
            kp_abs = self.detector.get_keypoints_absolute(results)

            if kp_norm is None or kp_abs is None:
                if is_video:
                    self.display_final_result(frame_cv, "NO POSE", 0, "Kh√¥ng t√¨m th·∫•y ng∆∞·ªùi", is_video)
                else:
                    self.after(0, lambda: self.lbl_img_result.configure(text="Kh√¥ng t√¨m th·∫•y ng∆∞·ªùi"))
                return

            # 2. Recognize & Evaluate
            pose_name, confidence = self.recognizer.recognize(kp_norm)
            score, feedback = self.evaluator.evaluate(pose_name, kp_abs)

            # 3. Draw & Overlay (V·∫Ω tr·ª±c ti·∫øp l√™n frame chu·∫©n)
            frame_drawn = self.drawer.draw(frame_cv.copy(), kp_abs, score)
            frame_final = self.overlay.draw_scoreboard(frame_drawn, pose_name, score, feedback)

            # 4. L∆∞u l·∫°i k·∫øt qu·∫£
            self.current_frame_processed = frame_final # Frame OpenCV (BGR)
            self.current_pose_name = pose_name  # Track for snapshots
            self.current_score = score  # Track for snapshots
            
            # 5. Hi·ªÉn th·ªã
            self.display_final_result(frame_final, pose_name, score, feedback, is_video)

        except Exception as e:
            print(f"Processing Error: {e}")

    def display_final_result(self, frame_cv, pose_name, score, feedback, is_video):
        # Convert BGR -> RGB ƒë·ªÉ hi·ªÉn th·ªã l√™n UI
        img_rgb = cv2.cvtColor(frame_cv, cv2.COLOR_BGR2RGB)
        pil_result = Image.fromarray(img_rgb)
        
        self.current_result_image = pil_result 

        if is_video:
            # Video c·∫ßn update li√™n t·ª•c
            self.display_image_on_label(pil_result, self.lbl_img_result)
            self.update_stats(pose_name, score, feedback)
        else:
            # ·∫¢nh th√¨ d√πng after ƒë·ªÉ tr√°nh xung ƒë·ªôt thread
            self.after(0, lambda: self.display_image_on_label(pil_result, self.lbl_img_result))
            self.after(0, lambda: self.update_stats(pose_name, score, feedback))

    def update_stats(self, pose, score, feedback):
        self.lbl_pose_name.configure(text=pose)
        
        score_val = score / 100.0
        self.progress_conf.set(score_val)
        self.lbl_conf_val.configure(text=f"{score}%")
        
        if score >= 80:
            self.progress_conf.configure(progress_color="#00E676")
        elif score >= 60:
            self.progress_conf.configure(progress_color="#FFEA00")
        else:
            self.progress_conf.configure(progress_color="#FF3D00")
            
        self.lbl_feedback.configure(text=feedback)

    def open_file_dialog(self):
        if self.is_video_mode:
            # Linux/Mac c·∫ßn d√πng space thay v√¨ semicolon
            file_path = filedialog.askopenfilename(
                title="Ch·ªçn Video",
                filetypes=[
                    ("Video files", "*.mp4 *.avi *.mov *.mkv"),
                    ("All files", "*.*")
                ]
            )
            if file_path:
                self.start_video(file_path)
        else:
            # Linux/Mac c·∫ßn d√πng space thay v√¨ semicolon
            file_path = filedialog.askopenfilename(
                title="Ch·ªçn ·∫¢nh",
                filetypes=[
                    ("Image files", "*.jpg *.jpeg *.png *.bmp"),
                    ("All files", "*.*")
                ]
            )
            if file_path:
                self.current_image_path = file_path
                threading.Thread(target=self.process_image_logic, args=(file_path,)).start()

    # -------------------------------------------------------------------------
    # H√ÄM HI·ªÇN TH·ªä ·∫¢NH L√äN UI (T·ª± ƒë·ªông scale ƒë·ªÉ FIT FULL khung)
    # -------------------------------------------------------------------------
    def display_image_on_label(self, pil_img, ctk_label):
        try:
            # 1. L·∫•y k√≠ch th∆∞·ªõc hi·ªán t·∫°i c·ªßa khung ch·ª©a (Label)
            w_widget = ctk_label.winfo_width()
            h_widget = ctk_label.winfo_height()
            
            if w_widget < 10 or h_widget < 10: return

            # Gi·∫£m k√≠ch th∆∞·ªõc hi·ªÉn th·ªã m·ªôt ch√∫t ƒë·ªÉ tr√°nh ch√®n vi·ªÅn
            safe_w = w_widget - 4
            safe_h = h_widget - 4

            # 2. T√≠nh to√°n t·ª∑ l·ªá ƒë·ªÉ "Contain" (Hi·ªÉn th·ªã to√†n b·ªô ·∫£nh)
            img_w, img_h = pil_img.size
            ratio_w = safe_w / img_w
            ratio_h = safe_h / img_h
            
            # Ch·ªçn t·ª∑ l·ªá nh·ªè h∆°n ƒë·ªÉ ƒë·∫£m b·∫£o ·∫£nh n·∫±m g·ªçn trong khung
            scale = min(ratio_w, ratio_h)
            
            display_w = int(img_w * scale)
            display_h = int(img_h * scale)

            # 3. T·∫°o CTkImage v·ªõi k√≠ch th∆∞·ªõc hi·ªÉn th·ªã ƒë√£ t√≠nh
            # L∆∞u √Ω: light_image/dark_image gi·ªØ nguy√™n ·∫£nh g·ªëc (ch·∫•t l∆∞·ª£ng cao)
            # size=(display_w, display_h) ch·ªâ ƒëi·ªÅu khi·ªÉn vi·ªác hi·ªÉn th·ªã tr√™n UI
            ctk_img = ctk.CTkImage(light_image=pil_img, dark_image=pil_img, size=(display_w, display_h))
            
            ctk_label.configure(image=ctk_img, text="")
            ctk_label.image = ctk_img # Gi·ªØ reference ƒë·ªÉ kh√¥ng b·ªã Garbage Collection thu h·ªìi
        except Exception as e:
            # print(f"Display error: {e}") 
            pass

    def on_frame_configure(self, event):
        """Khi resize c·ª≠a s·ªï, v·∫Ω l·∫°i ·∫£nh cho v·ª´a khung"""
        if self.is_video_mode:
            if self.is_paused and self.current_result_image:
                self.display_image_on_label(self.current_result_image, self.lbl_img_result)
        else:
            if self.current_pil_image:
                self.display_image_on_label(self.current_pil_image, self.lbl_img_input)
            if self.current_result_image:
                self.display_image_on_label(self.current_result_image, self.lbl_img_result)

    def change_appearance_mode_event(self, new_appearance_mode: str):
        ctk.set_appearance_mode(new_appearance_mode)
    
    def load_sample_images_ui(self):
        # Load sample images
        images = []
        for ext in ['*.jpg', '*.jpeg', '*.png']:
            images.extend(glob.glob(os.path.join("images", ext)))
            
        for i, img_path in enumerate(images[:10]):
            try:
                img = Image.open(img_path)
                ctk_thumb = ctk.CTkImage(img, size=(80, 80))
                btn = ctk.CTkButton(self.gallery_frame, image=ctk_thumb, text="", width=90, height=90,
                                    fg_color="transparent", border_width=2, border_color="gray",
                                    command=lambda p=img_path: self.open_file_dialog_manual(p))
                btn.grid(row=0, column=i, padx=5, pady=5)
            except: pass

    def open_file_dialog_manual(self, path):
        self.current_image_path = path
        if self.is_video_mode: self.switch_to_image_mode()
        threading.Thread(target=self.process_image_logic, args=(path,)).start()

if __name__ == "__main__":
    app = YogaApp()
    app.mainloop()